{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "37ae94b0d1fa26d6359ef95720f0ce70",
     "grade": false,
     "grade_id": "cell-609d2abf5d9435a8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<img src=\"https://brand.umich.edu/assets/brand/style-guide/logo-guidelines/U-M_Logo-Horizontal-Hex.png\" alt=\"Drawing\" style=\"width: 300px;\" align=\"left\"/><br>\n",
    "    \n",
    "## Week 2: Building prediction models of student success (20pts)\n",
    "\n",
    "Building prediction models of student success is one of the most prominent application of data science in education. Early detection of at-risk students will help the universities design in-time interventions and provide targeted support to those who were struggling. We will use the same OULAD dataset that you have worked on in week 1.\n",
    "\n",
    "**Overview of the dataset**\n",
    "\n",
    "The dataset contains the information about 22 courses, 32,593 students, their assessment results, and logs of their interactions with the Virtual Learning Environment (e.g., Moodle) represented by daily summaries of student clicks (10,655,280 entries). \n",
    "\n",
    "**Reference**\n",
    "\n",
    "Kuzilek, J., Hlosta, M., & Zdrahal, Z. (2017). Open university learning analytics dataset. Scientific data, 4, 170171. https://www.nature.com/articles/sdata2017171"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f3168031b4e75ebe1c16f4c3ad52b26c",
     "grade": false,
     "grade_id": "cell-4d443be60767370d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Open University Learning Analytics (OULAD) dataset\n",
    "\n",
    "Kuzilek, J., Hlosta, M., & Zdrahal, Z. (2017). Open university learning analytics dataset. Scientific data, 4, 170171. https://www.nature.com/articles/sdata2017171\n",
    "## Data scheme\n",
    "![](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fsdata.2017.171/MediaObjects/41597_2017_Article_BFsdata2017171_Fig2_HTML.jpg)\n",
    "## Course timeline\n",
    "![](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fsdata.2017.171/MediaObjects/41597_2017_Article_BFsdata2017171_Fig1_HTML.jpg)\n",
    "## Relational database\n",
    "* A module is a course\n",
    "* A presentation is a semester (e.g., 2019J - Fall 2019, 2019B = Winter 2019)\n",
    "* vle = virtual learning enviroment\n",
    "![](https://analyse.kmi.open.ac.uk/resources/images/model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7d5e1a8914eedcd795392aa4aac0f93f",
     "grade": false,
     "grade_id": "1A",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "## We only use data of BBB and FFF in 2013J and 2014J in this week assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d1d9a9bcec4611d45fad2c2819a822f5",
     "grade": false,
     "grade_id": "cell-43b4d2c3409bb05b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## A. Prepare the data (2pts)\n",
    "\n",
    "Load the data 'assets/studentInfo.csv'   \n",
    "Write a function that returns a pd.DataFrame of shape (6254, 39)\n",
    "\n",
    "* Create a new column ['outcome'], where outcome == 1 if students achieve a pass or a distinction, outcome == 0 if students failed\n",
    "* One-Hot Encode categorical features. Use dummies for multi-class features.\n",
    "* Do not encode ['id_student','code_module','code_presentation']\n",
    "* Make sure you only use data from BBB and FFF in 2013J and 2014J\n",
    "\n",
    "The final dataframe should consist of the following columns:\n",
    "\n",
    " 'code_module',  \n",
    " 'code_presentation',  \n",
    " 'id_student',  \n",
    " 'num_of_prev_attempts',  \n",
    " 'studied_credits',  \n",
    " 'outcome',    \n",
    " 'gender_F',  \n",
    " 'region_East Anglian Region',  \n",
    " 'region_East Midlands Region',  \n",
    " 'region_Ireland',  \n",
    " 'region_London Region',  \n",
    " 'region_North Region',  \n",
    " 'region_North Western Region',  \n",
    " 'region_Scotland',  \n",
    " 'region_South East Region',  \n",
    " 'region_South Region',  \n",
    " 'region_South West Region',  \n",
    " 'region_Wales',  \n",
    " 'region_West Midlands Region',  \n",
    " 'region_Yorkshire Region',  \n",
    " 'highest_education_A Level or Equivalent',  \n",
    " 'highest_education_HE Qualification',  \n",
    " 'highest_education_Lower Than A Level',  \n",
    " 'highest_education_No Formal quals',  \n",
    " 'highest_education_Post Graduate Qualification',  \n",
    " 'imd_band_0-10%',  \n",
    " 'imd_band_10-20',  \n",
    " 'imd_band_20-30%',  \n",
    " 'imd_band_30-40%',  \n",
    " 'imd_band_40-50%',  \n",
    " 'imd_band_50-60%',  \n",
    " 'imd_band_60-70%',  \n",
    " 'imd_band_70-80%',  \n",
    " 'imd_band_80-90%',  \n",
    " 'imd_band_90-100%',  \n",
    " 'age_band_0-35',  \n",
    " 'age_band_35-55',  \n",
    " 'age_band_55<=',  \n",
    " 'disability_Y'  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ac8850fc469021dd2d498988766e0e7a",
     "grade": false,
     "grade_id": "cell-d5cad898d284ed67",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a9441affded47802739b254df074dc9c",
     "grade": false,
     "grade_id": "cell-a358573cdc36c689",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_a():\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c7a42dca0b3f258925407720b47a54d5",
     "grade": true,
     "grade_id": "cell-ac53645cc62eac87",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Cell for autograder\n",
    "\n",
    "# Check data frame shape \n",
    "assert answer_a().shape == (6254, 39), \"Your pandas data frame should have 39 columns and 6254 rows\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2d740776112b6610b923fe4113a62d70",
     "grade": false,
     "grade_id": "cell-30a91542a522b1a3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## B. Feature engineering: assessments (3pts)\n",
    "\n",
    "For each unique combination of ['code_module','code_presentation','id_student'], create 3 new features: TMA1, TMA2, TMA3.\n",
    "* TMA1 is the the weighted score of 1st TMA rank by date \n",
    "* TMA2 is the the weighted score of 2nd TMA rank by date\n",
    "* TMA3 is the the weighted score of 3rd TMA rank by date \n",
    "\n",
    "Note:\n",
    "* Weighted_score = weight * score /100\n",
    "* If the students did not submit their TMA, then their score == 0. However, since those who did not submit TMA was not recorded in the studentAssessment.csv, you would need to think of a clever way to capture that information. Hint: You can use studentInfo.csv as a reference point. \n",
    "* Make sure you only use data from BBB and FFF in 2013J and 2014J\n",
    "\n",
    "The final dataframe should have a shape of (6254, 6) and it should consists of the following columns:\n",
    "* 'code_module' \n",
    "* 'code_presentation'\n",
    "* 'id_student'\n",
    "* 'TMA1'\n",
    "* 'TMA2'\n",
    "* 'TMA3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "15874237cbe51d7a214185027874cdcb",
     "grade": false,
     "grade_id": "cell-fb7949e696bc4c2f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_b():\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "eebe0b42922bd57531564c891ad1a17f",
     "grade": true,
     "grade_id": "cell-93791e2f717aa6be",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Cell for autograder\n",
    "\n",
    "# Data frame shape \n",
    "assert answer_b().shape == (6254, 6), \"Your data frame should have 6 columns and 6254 rows\"\n",
    "\n",
    "# Missing scores as 0\n",
    "assert answer_b()['TMA1'].isnull().sum() < 1, \"If the students did not submit their TMA, then their weighted score == 0\"\n",
    "assert answer_b()['TMA2'].isnull().sum() < 1, \"If the students did not submit their TMA, then their weighted score == 0\"\n",
    "assert answer_b()['TMA3'].isnull().sum() < 1, \"If the students did not submit their TMA, then their weighted score == 0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0b33c52953b21bad6f15fbb5b15be0e3",
     "grade": false,
     "grade_id": "cell-e52134c4660cfebb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "## C. Feature engineering: VLE activities (3pts)\n",
    "\n",
    "Write a function that summarizes the number of clicks on each course section during day [0,100] for each student. It should returns a pd.dataframe with the shape of (6254,7) with the following columns:\n",
    "* 'code_module'\n",
    "* 'code_presentation'\n",
    "* 'id_student'\n",
    "\n",
    "And compute the sum of click for:\n",
    "* 'forumng'\n",
    "* 'homepage'\n",
    "* 'oucontent'\n",
    "* 'resource'\n",
    "* 'glossary'\n",
    "* 'oucollaborate'\n",
    "* 'quiz'\n",
    "* 'subpage'\n",
    "* 'url'\n",
    "\n",
    "**Note**: \n",
    "* Missing data should be replaced by 0, which means that the students did not click on that course section\n",
    "* Make sure you only use data from BBB and FFF in 2013J and 2014J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f6402ce6d61f6e075ced5472d7674a2e",
     "grade": false,
     "grade_id": "cell-deecda829abc55a0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_c():\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b7c1d2c2ead824425311fbe12d233e5b",
     "grade": true,
     "grade_id": "cell-7a56d7548555b6e7",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Cell for autograder\n",
    "ans_c = answer_c()\n",
    "\n",
    "# Data frame shape \n",
    "assert ans_c.shape == (6254, 12), \"Your data frame should have 7 columns and 6254 rows\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d05110bbc363ca1d29ff69465cab2ae3",
     "grade": false,
     "grade_id": "cell-9100d3dc065b725a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## D. Feature extraction: PCA (3pts)\n",
    "\n",
    "Many of the features from VLE activities are highly correlated (e.g. if students click on homepage, they will be likely to click on oucontent). One way to reduce the number of highly correlated features is to perform a Principal Component Analysis (PCA).\n",
    "\n",
    "Write a function\n",
    "* Perform a PCA on the four VLE features in answer_c(): forumng, homepage, oucontent, resource. Make sure to standardize the features before run the PCA.\n",
    "* Select the number of k components such that the **cummulative variance explained ratio > 0.8**\n",
    "* Return a pd.dataframe that consist of: 'code_module','code_presentation','id_student', and the principal components that you chose. For example, if you choose k=2 then the columns should be PC1, PC2. If you choose k=3, then the columns should be PC1,PC2,PC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cfc8d0237d8219f5289ee19fd3559b71",
     "grade": false,
     "grade_id": "cell-ab040af060a08f78",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_d():\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.decomposition import PCA\n",
    "    df = answer_c()\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "87cc87a75f7b5ded711ba4653ed3e272",
     "grade": true,
     "grade_id": "cell-6a1bff4e9ec54030",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Cell for autograder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The subsequent questions will depend on the previous output. So make sure you submit the assignment at this point to ensure you got the right output before moving on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Train-test split (3pts)\n",
    "\n",
    "Write a function that\n",
    "* Combine all the features from answer_a(), answer_b(), and answer_d() into a single dataframe\n",
    "* Perform a feature scaling on the merged data using Standard Scaler\n",
    "* Split the data into a traing set and a test set, make sure to use stratified sample because we have imbalanced data \n",
    "* Return X_train, X_test, y_train, y_test as np.arrays\n",
    "\n",
    "Note: \n",
    "* Whenever appropriate, using a random_state =42\n",
    "* 'code_module','code_presentation','id_student' should be excluded in the feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "aa3d6c160ee7ddae16687eb3d0d37f76",
     "grade": false,
     "grade_id": "cell-79a80c39bff1b90c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_e():\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    # Call data from the previous answers\n",
    "    a = answer_a()\n",
    "    b = answer_b()\n",
    "    d = answer_d()\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "92dc89832b5b1aeec6182370678702a7",
     "grade": true,
     "grade_id": "cell-a9719881fe952dbb",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Cell for autograder\n",
    "X_train, X_test, y_train, y_test = answer_e()\n",
    "\n",
    "# Data length\n",
    "assert X_train.shape == (4690, 43), \"There should be 4690 data points and 40 features in the train set\"\n",
    "assert X_test.shape == (1564, 43), \"There should be 1564 data points and 40 features in the test set\"\n",
    "\n",
    "# Feature normalization\n",
    "assert (X_train < 200).all(), \"You should perform a feature scaling after spliting the data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F. Apply classification algorithms (3pts)\n",
    "\n",
    "Write a function that applies four different classification algorithms using the training and testing sets obtained from answer_e():\n",
    "* Logistic Regression (random_state=42)\n",
    "* Random Forest (random_state=42)\n",
    "* Support Vector Machine (random_state=42)\n",
    "* K-Nearest Neighbour (n_neighbors=5)\n",
    "\n",
    "Return a pd.dataframe of shape (4,4) with the following columns ['Accuracy','Recall', 'Precision', 'Model']\n",
    "\n",
    "**Resources**: You can find more details about the pros and cons of each alogrithm [here](https://towardsdatascience.com/comparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "875f5d7ceb652871556aa7d330dfc896",
     "grade": false,
     "grade_id": "cell-1db2daa798f1d085",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_f():\n",
    "    from sklearn.metrics import recall_score, precision_score\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    \n",
    "    # Call data from the previous answers\n",
    "    X_train, X_test, y_train, y_test = answer_e()\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bdd7826e0ec2be9a1f96718aed71b496",
     "grade": true,
     "grade_id": "cell-ad22bdd64323f96d",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Cell for autograder\n",
    "ans_f = answer_f()\n",
    "\n",
    "# Data frame shape \n",
    "assert ans_f.shape == (4,4), \"Your data frame should 4 rows and 4 columns\"\n",
    "\n",
    "# Check accuracy of LR \n",
    "actual =  ans_f.loc[ans_f['Model']=='Logistic Regression']['Accuracy'].values \n",
    "desired = 0.862532\n",
    "np.testing.assert_almost_equal(actual, desired, decimal=4, err_msg='The accuracy of Logistic Regression is not correct', verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "896120f56ec79438ba6d14eae2ed7348",
     "grade": false,
     "grade_id": "cell-012fc2c3449cd120",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run to plot your result \n",
    "df=answer_f().melt('Model', var_name='Metrics', value_name='Value')\n",
    "sns.barplot(x=\"Metrics\", y=\"Value\", hue=\"Model\", data=df)\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e7d719ad361ff475165769ce83cbd82d",
     "grade": false,
     "grade_id": "cell-64e8ded9e3e17062",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## G. Model evaluation (3pts)\n",
    "\n",
    "Write a function that applies 2 different classification algorithms using 10-fold [stratified cross validation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html):\n",
    "\n",
    "* Logistic regression\n",
    "* Random forest\n",
    "\n",
    "For each algorithm, return the mean roc_auc and standard deviation roc_auc\n",
    "The final output should be a pd.DataFrame with the folliwng columns: 'mean_auc_score','std_auc_score','model'\n",
    "\n",
    "Note: \n",
    "* While running the [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html), you can speed up the processing time by setting the number of jobs to run in parallel (e.g., n_jobs = 2) to make use of multi-core processing. See more in the documentation\n",
    "* Make sure you use random_state=42 in setting up the StratifiedKFold, LogisticRegression, and RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fd7aa105fe9b847c9f0889c5a056c31b",
     "grade": false,
     "grade_id": "cell-fe5e69c9a1fee984",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_g():\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    \n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    # Call data from the previous answers\n",
    "    X_train, X_test, y_train, y_test = answer_e()\n",
    "    X = np.concatenate((X_train,X_test), axis=0)\n",
    "    y = np.concatenate((y_train,y_test), axis=0)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d0db90c6638a135fb25b0bfda0a4434c",
     "grade": true,
     "grade_id": "cell-d767629e5a66507c",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Cell for autograder\n",
    "ans_g = answer_g()\n",
    "\n",
    "# Data frame shape \n",
    "assert ans_g.shape == (2,3), \"Your data frame should 4 rows and 4 columns\"\n",
    "\n",
    "# Check mean_auc_score of LR\n",
    "actual =  ans_g.loc[ans_g['model']=='Logistic Regression']['mean_auc_score'].values \n",
    "desired = 0.89835\n",
    "np.testing.assert_almost_equal(actual, desired, decimal=4, err_msg='The accuracy of Logistic Regression is not correct', verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
